# LLM Provider API Keys - Iteration 1
# Only set ONE of the following based on which provider you're using

# For Claude (Anthropic)
ANTHROPIC_API_KEY=your_api_key_here

# For OpenAI
OPENAI_API_KEY=your_api_key_here

# For Ollama
# If running locally, leave blank or set to http://localhost:11434
# If running remotely, set to your Ollama server URL
OLLAMA_HOST=http://localhost:11434
